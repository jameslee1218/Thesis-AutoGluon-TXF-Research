{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ILMbqCA2DkW",
        "outputId": "0cfff42e-59b6-4834-d21f-4464678f8c78"
      },
      "source": [
        "#@markdown #掛載Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74900717",
        "outputId": "039254b1-5633-4917-a20c-e8a868b59dda"
      },
      "source": [
        "!pip install scikit-optimize"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.3)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-26.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (26.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-26.2.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-26.2.1 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovoIGwag1kHv"
      },
      "source": [
        "\"\"\"\n",
        "技術指標 Autoencoder 壓縮訓練腳本\n",
        "將同類技術指標壓縮為單一數值\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import io\n",
        "\n",
        "# 設定輸出編碼為 UTF-8（解決 Windows 控制台編碼問題）\n",
        "if sys.platform == 'win32':\n",
        "    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')\n",
        "    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import json\n",
        "import random\n",
        "\n",
        "# 在導入 TensorFlow 之前設定環境變數（幫助 TensorFlow 找到 CUDA）\n",
        "# 這可以幫助 TensorFlow 在 Windows 上找到 CUDA 庫\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # 減少 TensorFlow 日誌輸出\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # 關閉 oneDNN 選項\n",
        "\n",
        "# 深度學習相關\n",
        "import tensorflow as tf\n",
        "# TensorFlow 2.10+ 中，keras 是獨立包，需要使用 keras.src\n",
        "import keras\n",
        "from keras.src import layers, models, callbacks\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "from skopt.utils import use_named_args\n",
        "\n",
        "# 圖表和輸出\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # 使用非交互式後端\n",
        "import openpyxl\n",
        "from openpyxl.drawing.image import Image\n",
        "import io\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xge3JyZ02WFS"
      },
      "source": [
        "# ==================== 可調整參數 ====================\n",
        "# 技術指標群組定義\n",
        "INDICATOR_GROUPS = {\n",
        "    \"STOCH\": [\"STOCH_K_14\", \"STOCH_D_14\"],\n",
        "    \"STOCHF\": [\"STOCHF_K_14\", \"STOCHF_D_14\"],\n",
        "    \"STOCHRSI\": [\"STOCHRSI_K_14\", \"STOCHRSI_D_14\"],\n",
        "    \"MACD\": [\"MACD_12_26\", \"MACD_signal_12_26\", \"MACD_hist_12_26\"],\n",
        "    \"BBANDS\": [\"BBANDS_upper_20\", \"BBANDS_middle_20\", \"BBANDS_lower_20\"],\n",
        "    \"ADX_DMI\": [\"ADX_14\", \"ADXR_14\", \"PDI_14\", \"MDI_14\", \"DX_14\"],\n",
        "    \"AROON\": [\"AROON_Down_14\", \"AROON_Up_14\", \"AROONOSC_14\"]\n",
        "}\n",
        "\n",
        "# 資料路徑"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHhuqwjh2XN1"
      },
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/工作區/論文/論文code/1106/technical_indicators_data_extracted\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/工作區/論文/論文code/1106/output2\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4ASDp2z20_C",
        "outputId": "a73fce6e-af67-4b4a-bc5d-b7231376cdfb"
      },
      "source": [
        "import os\n",
        "\n",
        "def list_top_n_files(directory, n=5):\n",
        "    \"\"\"Lists the first n files in a given directory.\"\"\"\n",
        "    if not os.path.isdir(directory):\n",
        "        print(f\"Error: Directory not found: {directory}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nListing first {n} files in: {directory}\")\n",
        "    try:\n",
        "        files = os.listdir(directory)\n",
        "        # Sort files to get a consistent order\n",
        "        files.sort()\n",
        "        for i, file in enumerate(files[:n]):\n",
        "            print(f\"- {file}\")\n",
        "        if len(files) > n:\n",
        "            print(f\"... and {len(files) - n} more files\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error listing files in {directory}: {e}\")\n",
        "\n",
        "# List files in DATA_DIR\n",
        "list_top_n_files(DATA_DIR)\n",
        "\n",
        "# List files in OUTPUT_DIR\n",
        "list_top_n_files(OUTPUT_DIR)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Listing first 5 files in: /content/drive/MyDrive/工作區/論文/論文code/1106/technical_indicators_data_extracted\n",
            "- TX20110103_1K_qlib_indicators_complete.csv\n",
            "- TX20110104_1K_qlib_indicators_complete.csv\n",
            "- TX20110105_1K_qlib_indicators_complete.csv\n",
            "- TX20110106_1K_qlib_indicators_complete.csv\n",
            "- TX20110107_1K_qlib_indicators_complete.csv\n",
            "... and 2719 more files\n",
            "\n",
            "Listing first 5 files in: /content/drive/MyDrive/工作區/論文/論文code/1106/output2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZxLibj32ZJd"
      },
      "source": [
        "# ======== 全域參數（避免重複定義） ========\n",
        "VAL_SPLIT = 0.2  # 只用於 Train 內的驗證切分\n",
        "\n",
        "ENCODER_DIMS = [256, 128]\n",
        "DECODER_DIMS = [128, 256]\n",
        "\n",
        "# Dropout 刻度（0~0.4 常見甜區）\n",
        "DROPOUT_RATES = [0.0, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
        "\n",
        "# Batch size（依 GPU 記憶體調整）\n",
        "BATCH_SIZE = 32786\n",
        "\n",
        "# ==== 貝葉斯優化參數 ====\n",
        "BAYESIAN_N_CALLS = 24\n",
        "\n",
        "# 訓練參數\n",
        "EARLY_STOPPING_PATIENCE = 16\n",
        "MAX_EPOCHS = 300\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# 搜索階段的早停耐心（較短，加快搜索）\n",
        "SEARCH_EARLY_STOPPING_PATIENCE = 8\n",
        "\n",
        "# 優化選項\n",
        "SKIP_FINAL_TRAINING = True  # True：跳過最終訓練，直接用搜尋階段最佳模型\n",
        "\n",
        "# ==================== 超參數搜尋空間 ====================\n",
        "# 固定瓶頸層大小（全部壓成 1 維）\n",
        "FIXED_BOTTLENECK = 1\n",
        "\n",
        "# 改為連續取值（log-uniform 分佈）\n",
        "from skopt.space import Real, Integer\n",
        "LEARNING_RATE_SPACE = Real(3e-4, 2e-3, prior='log-uniform', name='learning_rate')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CZTD0GZtiBS"
      },
      "source": [],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAvJqfj-ouPz",
        "outputId": "2d034ee7-814d-47f7-b0c0-c7bf43083936"
      },
      "source": [
        "# @title\n",
        "# ==================== 設定隨機種子 ====================\n",
        "def set_random_seeds(seed):\n",
        "    \"\"\"設定所有隨機種子以確保可重現性\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_random_seeds(RANDOM_SEED)\n",
        "\n",
        "# ==================== 資料載入 ====================\n",
        "def load_all_data(data_dir):\n",
        "    \"\"\"載入所有CSV檔案並合併\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"[LOAD] 載入資料...\")\n",
        "\n",
        "    csv_files = glob.glob(os.path.join(data_dir, \"TX*_1K_qlib_indicators_complete.csv\"))\n",
        "    csv_files.sort()  # 按檔名排序以確保時間順序\n",
        "\n",
        "    print(f\"找到 {len(csv_files)} 個CSV檔案\")\n",
        "\n",
        "    all_data = []\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            df = pd.read_csv(file)\n",
        "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "            all_data.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] 讀取檔案失敗: {os.path.basename(file)} - {e}\")\n",
        "\n",
        "    if not all_data:\n",
        "        raise ValueError(\"[ERROR] 沒有成功載入任何資料！\")\n",
        "\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    combined_df = combined_df.sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "    print(f\"[OK] 成功載入資料，總共 {len(combined_df):,} 筆記錄\")\n",
        "    print(f\"[INFO] 時間範圍: {combined_df['datetime'].min()} 至 {combined_df['datetime'].max()}\")\n",
        "\n",
        "    return combined_df\n",
        "df = load_all_data(DATA_DIR)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "[LOAD] 載入資料...\n",
            "找到 2723 個CSV檔案\n",
            "[OK] 成功載入資料，總共 819,623 筆記錄\n",
            "[INFO] 時間範圍: 2011-01-03 08:45:00 至 2023-12-22 13:45:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3UFIBJ42QDg",
        "outputId": "4de73452-32e8-4724-f021-99a4d45664ea"
      },
      "source": [
        "# @title\n",
        "# ==================== 資料切分（3 年視窗：前 2 年訓練、後 1 年測試） ====================\n",
        "def split_train_val_by_date(df_in, val_split=0.2):\n",
        "    \"\"\"只在訓練資料內做 Train/Val 切分（以交易日為單位）\"\"\"\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df_in['datetime']):\n",
        "        df_in['datetime'] = pd.to_datetime(df_in['datetime'])\n",
        "\n",
        "    unique_dates = sorted(df_in['datetime'].dt.date.unique())\n",
        "    if len(unique_dates) < 2:\n",
        "        raise ValueError(\"[ERROR] 訓練資料日期不足，無法切分 Train/Val\")\n",
        "\n",
        "    n_days = len(unique_dates)\n",
        "    n_val_days = max(1, int(n_days * val_split))\n",
        "    n_train_days = n_days - n_val_days\n",
        "\n",
        "    val_start_date = unique_dates[n_train_days]\n",
        "\n",
        "    train_mask = df_in['datetime'].dt.date < val_start_date\n",
        "    val_mask = df_in['datetime'].dt.date >= val_start_date\n",
        "\n",
        "    train_df = df_in[train_mask].copy()\n",
        "    val_df = df_in[val_mask].copy()\n",
        "\n",
        "    print(\"[SPLIT] Train/Val by trading day\")\n",
        "    print(f\"  訓練集天數: {n_train_days}\")\n",
        "    print(f\"  驗證集天數: {n_val_days}\")\n",
        "    print(f\"  Cutoff (Train|Val): {val_start_date}\")\n",
        "    print(f\"  訓練集: {len(train_df):,} 筆 | 時間: {train_df['datetime'].min()} 至 {train_df['datetime'].max()}\")\n",
        "    print(f\"  驗證集: {len(val_df):,} 筆 | 時間: {val_df['datetime'].min()} 至 {val_df['datetime'].max()}\")\n",
        "\n",
        "    return train_df, val_df\n",
        "\n",
        "\n",
        "def build_rolling_windows_by_year(df_in, window_years=3):\n",
        "    \"\"\"建立可用的 3 年滾動視窗（若年份缺失則跳過該視窗）\"\"\"\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df_in['datetime']):\n",
        "        df_in['datetime'] = pd.to_datetime(df_in['datetime'])\n",
        "\n",
        "    data_years = sorted(df_in['datetime'].dt.year.unique())\n",
        "    if len(data_years) < window_years:\n",
        "        raise ValueError(\"[ERROR] 資料年份不足 3 年，無法進行 3 年滾動視窗。\")\n",
        "\n",
        "    full_years = list(range(data_years[0], data_years[-1] + 1))\n",
        "    windows = []\n",
        "    for i in range(len(full_years) - window_years + 1):\n",
        "        window = full_years[i:i + window_years]\n",
        "        if all(y in data_years for y in window):\n",
        "            windows.append(window)\n",
        "        else:\n",
        "            missing = [y for y in window if y not in data_years]\n",
        "            print(f\"[WARN] 跳過視窗 {window[0]}-{window[-1]}，缺少年份: {missing}\")\n",
        "\n",
        "    if not windows:\n",
        "        raise ValueError(\"[ERROR] 沒有可用的完整 3 年視窗。\")\n",
        "\n",
        "    return windows\n",
        "\n",
        "# ==================== 資料準備 ====================\n",
        "def prepare_indicator_data(df, indicator_cols):\n",
        "    \"\"\"準備指定指標的資料\"\"\"\n",
        "    missing_cols = [col for col in indicator_cols if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"[ERROR] 缺少欄位: {missing_cols}\")\n",
        "\n",
        "    data = df[indicator_cols].values\n",
        "    data = np.nan_to_num(data, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "    return data\n",
        "\n",
        "# ==================== Autoencoder 模型 ====================\n",
        "def build_autoencoder(input_dim, bottleneck_size, dropout_rate=0.0):\n",
        "    \"\"\"建立 Autoencoder 模型\n",
        "\n",
        "    架構: Input → 256 → 128 → bottleneck → 128 → 256 → Output\n",
        "    \"\"\"\n",
        "    input_layer = layers.Input(shape=(input_dim,), name='input')\n",
        "\n",
        "    # 編碼器\n",
        "    x = layers.Dense(ENCODER_DIMS[0], activation='relu', name='encoder_1')(input_layer)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    x = layers.Dense(ENCODER_DIMS[1], activation='relu', name='encoder_2')(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    bottleneck = layers.Dense(bottleneck_size, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # 解碼器\n",
        "    x = layers.Dense(DECODER_DIMS[0], activation='relu', name='decoder_1')(bottleneck)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    x = layers.Dense(DECODER_DIMS[1], activation='relu', name='decoder_2')(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    output = layers.Dense(input_dim, activation='linear', name='output')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output, name='autoencoder')\n",
        "    return model\n",
        "\n",
        "# ==================== 訓練函數 ====================\n",
        "def train_autoencoder(X_train, X_val, bottleneck_size, lr, dropout_rate, batch_size,\n",
        "                     max_epochs=200, patience=12, group_name=\"\", show_progress=False):\n",
        "    \"\"\"訓練單一 Autoencoder\"\"\"\n",
        "    input_dim = X_train.shape[1]\n",
        "\n",
        "    model = build_autoencoder(input_dim, bottleneck_size, dropout_rate)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
        "\n",
        "    early_stopping = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=patience,\n",
        "        restore_best_weights=True,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    history_callback = callbacks.History()\n",
        "\n",
        "    class ProgressCallback(callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            if show_progress and (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{max_epochs}, Loss: {logs['loss']:.6f}, Val Loss: {logs['val_loss']:.6f}\",\n",
        "                      end='\\r', flush=True)\n",
        "\n",
        "    progress_callback = ProgressCallback() if show_progress else None\n",
        "\n",
        "    train_start_time = datetime.now()\n",
        "\n",
        "    callbacks_list = [early_stopping, history_callback]\n",
        "    if progress_callback:\n",
        "        callbacks_list.append(progress_callback)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, X_train,\n",
        "        validation_data=(X_val, X_val),\n",
        "        epochs=max_epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks_list,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    train_end_time = datetime.now()\n",
        "    train_duration = (train_end_time - train_start_time).total_seconds()\n",
        "\n",
        "    n_epochs = len(history.history['loss'])\n",
        "    if n_epochs > 0:\n",
        "        time_per_epoch = train_duration / n_epochs\n",
        "        epoch_times = [time_per_epoch * (i + 1) for i in range(n_epochs)]\n",
        "        history.history['epoch_times'] = epoch_times\n",
        "        history.history['total_time'] = train_duration\n",
        "    else:\n",
        "        history.history['epoch_times'] = []\n",
        "        history.history['total_time'] = 0\n",
        "\n",
        "    return model, history.history\n",
        "\n",
        "# ==================== 超參數搜尋（貝葉斯優化） ====================\n",
        "def hyperparameter_search(X_train, X_val, group_name, indicator_cols):\n",
        "    \"\"\"使用貝葉斯優化進行超參數搜尋\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[SEARCH] 開始貝葉斯優化超參數搜尋: {group_name}\")\n",
        "    print(f\"   輸入維度: {len(indicator_cols)}\")\n",
        "    print(f\"   優化迭代次數: {BAYESIAN_N_CALLS}\")\n",
        "\n",
        "    input_dim = len(indicator_cols)\n",
        "    print(f\"   Bottleneck 固定為: {FIXED_BOTTLENECK}（將 {input_dim} 維壓縮為 1 維）\")\n",
        "\n",
        "    assert len(DROPOUT_RATES) >= 2, f\"Dropout 候選必須至少 2 個，當前: {DROPOUT_RATES}\"\n",
        "\n",
        "    dimensions = [\n",
        "        LEARNING_RATE_SPACE,\n",
        "        Integer(0, len(DROPOUT_RATES) - 1, name='dropout_idx'),\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    best_val_mse = float('inf')\n",
        "    best_config = None\n",
        "    best_model = None\n",
        "    best_history = None\n",
        "    iteration_count = [0]\n",
        "\n",
        "    search_start_time = datetime.now()\n",
        "\n",
        "    @use_named_args(dimensions=dimensions)\n",
        "    def objective(learning_rate, dropout_idx):\n",
        "        iteration_count[0] += 1\n",
        "        idx = iteration_count[0]\n",
        "\n",
        "        bottleneck = FIXED_BOTTLENECK\n",
        "        lr = float(learning_rate)\n",
        "        dropout = DROPOUT_RATES[int(dropout_idx)]\n",
        "        batch = BATCH_SIZE\n",
        "\n",
        "        config = {\n",
        "            'bottleneck': bottleneck,\n",
        "            'lr': lr,\n",
        "            'dropout': dropout,\n",
        "            'batch': batch\n",
        "        }\n",
        "\n",
        "        progress = (idx - 1) / BAYESIAN_N_CALLS * 100\n",
        "        elapsed_time = (datetime.now() - search_start_time).total_seconds()\n",
        "\n",
        "        print(f\"\\n  [貝葉斯優化 {progress:.1f}%] [{idx}/{BAYESIAN_N_CALLS}] 測試組合:\")\n",
        "        print(f\"    Bottleneck: {bottleneck}, LR: {lr:.0e}, \"\n",
        "              f\"Dropout: {dropout}, Batch: {batch}\")\n",
        "\n",
        "        if idx > 1:\n",
        "            avg_time = elapsed_time / (idx - 1)\n",
        "            remaining = avg_time * (BAYESIAN_N_CALLS - idx + 1)\n",
        "            print(f\"    已用時間: {elapsed_time:.1f}秒 | 預計剩餘: {remaining:.1f}秒\")\n",
        "\n",
        "        try:\n",
        "            print(\"    [訓練中...] \", end='', flush=True)\n",
        "            model, history = train_autoencoder(\n",
        "                X_train, X_val,\n",
        "                bottleneck_size=bottleneck,\n",
        "                lr=lr,\n",
        "                dropout_rate=dropout,\n",
        "                batch_size=batch,\n",
        "                max_epochs=MAX_EPOCHS,\n",
        "                patience=SEARCH_EARLY_STOPPING_PATIENCE,\n",
        "                group_name=group_name\n",
        "            )\n",
        "\n",
        "            best_val = float(np.min(history['val_loss']))\n",
        "\n",
        "            if 'total_time' in history:\n",
        "                epochs = len(history.get('loss', []))\n",
        "                print(f\"[完成] 訓練時間: {history['total_time']:.2f}秒 ({epochs} epochs)\")\n",
        "\n",
        "            print(f\"    [結果] 最佳 Val Loss: {best_val:.6f}\")\n",
        "\n",
        "            nonlocal best_val_mse, best_config, best_model, best_history\n",
        "            is_better = False\n",
        "            if best_val < best_val_mse * 0.99:\n",
        "                is_better = True\n",
        "            elif best_config is not None and best_val <= best_val_mse * 1.01:\n",
        "                is_better = True\n",
        "\n",
        "            train_mse = None\n",
        "            val_mse = None\n",
        "            if is_better:\n",
        "                print(\"[評估中...] \", end='', flush=True)\n",
        "                val_pred = model.predict(X_val, verbose=0)\n",
        "                val_mse = mean_squared_error(X_val, val_pred)\n",
        "\n",
        "                train_pred = model.predict(X_train, verbose=0)\n",
        "                train_mse = mean_squared_error(X_train, train_pred)\n",
        "\n",
        "                print(f\"[完成] Train MSE: {train_mse:.6f}, Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "                best_val_mse = best_val\n",
        "                best_config = config\n",
        "                best_model = model\n",
        "                best_history = history\n",
        "                print(\"    [BEST] 更新最佳模型！\")\n",
        "\n",
        "            result = {\n",
        "                'config': config,\n",
        "                'train_mse': train_mse,\n",
        "                'val_mse': val_mse,\n",
        "                'best_val_loss': best_val,\n",
        "                'model': model if is_better else None,\n",
        "                'history': history\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            return best_val\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    [ERROR] 訓練失敗: {e}\")\n",
        "            return 1e10\n",
        "\n",
        "    print(\"\\n[INFO] 開始貝葉斯優化（高斯過程）...\")\n",
        "    result_optimization = gp_minimize(\n",
        "        func=objective,\n",
        "        dimensions=dimensions,\n",
        "        n_calls=BAYESIAN_N_CALLS,\n",
        "        random_state=RANDOM_SEED,\n",
        "        n_initial_points=min(4, BAYESIAN_N_CALLS),\n",
        "        acq_func='EI',\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    if best_config is None:\n",
        "        raise ValueError(f\"[ERROR] {group_name} 沒有成功的訓練結果！\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[BEST] 最佳超參數 ({group_name}):\")\n",
        "    print(f\"   Bottleneck: {FIXED_BOTTLENECK} (固定)\")\n",
        "    print(f\"   Learning Rate: {best_config['lr']:.0e}\")\n",
        "    print(f\"   Dropout: {best_config['dropout']}\")\n",
        "    print(f\"   Batch Size: {best_config['batch']}\")\n",
        "    print(f\"   最佳驗證損失: {best_val_mse:.6f}\")\n",
        "    best_result = next((r for r in results if r.get('val_mse') is not None and r['config'] == best_config), None)\n",
        "    if best_result:\n",
        "        print(f\"   驗證集 MSE: {best_result['val_mse']:.6f}\")\n",
        "    print(f\"\\n[INFO] 貝葉斯優化找到的最佳目標值: {result_optimization.fun:.6f}\")\n",
        "    print(f\"[INFO] 最佳參數位置: {result_optimization.x}\")\n",
        "\n",
        "    return best_model, best_config, best_history, results\n",
        "\n",
        "# ==================== 最終訓練 ====================\n",
        "def final_training(X_train, X_val, X_test, best_config, group_name, best_model=None):\n",
        "    \"\"\"使用最佳參數在 Train+Val 上重訓，評估 Test\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[FINAL] 最終訓練: {group_name}\")\n",
        "    print(\"   使用 Train+Val 資料重新訓練...\")\n",
        "\n",
        "    X_train_val = np.vstack([X_train, X_val])\n",
        "\n",
        "    n_val_final = int(len(X_train_val) * 0.2)\n",
        "    X_train_final = X_train_val[:-n_val_final]\n",
        "    X_val_final = X_train_val[-n_val_final:]\n",
        "\n",
        "    print(f\"   最終訓練集: {len(X_train_final):,} 筆\")\n",
        "    print(f\"   最終驗證集: {len(X_val_final):,} 筆（用於早停）\")\n",
        "    print(f\"   測試集: {len(X_test):,} 筆\")\n",
        "\n",
        "    if best_model is not None:\n",
        "        print(\"   [優化] 使用遷移學習：從搜索階段最佳模型繼續訓練（節省時間）\")\n",
        "        input_dim = X_train_final.shape[1]\n",
        "\n",
        "        model = build_autoencoder(\n",
        "            input_dim,\n",
        "            best_config['bottleneck'],\n",
        "            best_config['dropout']\n",
        "        )\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=best_config['lr'])\n",
        "        model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
        "\n",
        "        try:\n",
        "            best_layers = best_model.layers\n",
        "            new_layers = model.layers\n",
        "\n",
        "            for best_layer, new_layer in zip(best_layers, new_layers):\n",
        "                if len(best_layer.get_weights()) > 0 and len(new_layer.get_weights()) > 0:\n",
        "                    if (best_layer.get_weights()[0].shape == new_layer.get_weights()[0].shape and\n",
        "                        len(best_layer.get_weights()) == len(new_layer.get_weights())):\n",
        "                        new_layer.set_weights(best_layer.get_weights())\n",
        "            print(\"   ✅ 權重遷移成功\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ 權重遷移失敗，將從頭訓練: {e}\")\n",
        "\n",
        "        early_stopping = callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=EARLY_STOPPING_PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        history_callback = callbacks.History()\n",
        "        train_start_time = datetime.now()\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train_final, X_train_final,\n",
        "            validation_data=(X_val_final, X_val_final),\n",
        "            epochs=MAX_EPOCHS,\n",
        "            batch_size=best_config['batch'],\n",
        "            callbacks=[early_stopping, history_callback],\n",
        "            verbose=0,\n",
        "            initial_epoch=0\n",
        "        )\n",
        "\n",
        "        train_end_time = datetime.now()\n",
        "        train_duration = (train_end_time - train_start_time).total_seconds()\n",
        "\n",
        "        n_epochs = len(history.history['loss'])\n",
        "        if n_epochs > 0:\n",
        "            time_per_epoch = train_duration / n_epochs\n",
        "            epoch_times = [time_per_epoch * (i + 1) for i in range(n_epochs)]\n",
        "            history.history['epoch_times'] = epoch_times\n",
        "            history.history['total_time'] = train_duration\n",
        "        else:\n",
        "            history.history['epoch_times'] = []\n",
        "            history.history['total_time'] = 0\n",
        "\n",
        "        history = history.history\n",
        "    else:\n",
        "        model, history = train_autoencoder(\n",
        "            X_train_final, X_val_final,\n",
        "            bottleneck_size=best_config['bottleneck'],\n",
        "            lr=best_config['lr'],\n",
        "            dropout_rate=best_config['dropout'],\n",
        "            batch_size=best_config['batch'],\n",
        "            max_epochs=MAX_EPOCHS,\n",
        "            patience=EARLY_STOPPING_PATIENCE,\n",
        "            group_name=group_name\n",
        "        )\n",
        "\n",
        "    epochs = len(history.get('loss', []))\n",
        "    train_time = history.get('total_time', 0)\n",
        "    print(f\"[完成] 訓練時間: {train_time:.2f}秒 ({epochs} epochs)\")\n",
        "\n",
        "    print(\"   [評估中...] \", end='', flush=True)\n",
        "\n",
        "    train_val_pred = model.predict(X_train_val, verbose=0)\n",
        "    test_pred = model.predict(X_test, verbose=0)\n",
        "\n",
        "    train_val_mse = mean_squared_error(X_train_val, train_val_pred)\n",
        "    test_mse = mean_squared_error(X_test, test_pred)\n",
        "\n",
        "    train_pred_only = model.predict(X_train, verbose=0)\n",
        "    val_pred_only = model.predict(X_val, verbose=0)\n",
        "    train_mse = mean_squared_error(X_train, train_pred_only)\n",
        "    val_mse = mean_squared_error(X_val, val_pred_only)\n",
        "\n",
        "    print(\"[完成]\")\n",
        "    print(f\"   [結果] Train MSE: {train_mse:.6f}\")\n",
        "    print(f\"   [結果] Val MSE: {val_mse:.6f}\")\n",
        "    print(f\"   [結果] Train+Val MSE: {train_val_mse:.6f}\")\n",
        "    print(f\"   [結果] Test MSE: {test_mse:.6f}\")\n",
        "\n",
        "    return model, {\n",
        "        'train_mse': train_mse,\n",
        "        'val_mse': val_mse,\n",
        "        'train_val_mse': train_val_mse,\n",
        "        'test_mse': test_mse,\n",
        "        'history': history\n",
        "    }\n",
        "\n",
        "# ==================== 壓縮並保存資料 ====================\n",
        "def compress_and_save_data(model, scaler, df_to_compress, indicator_cols, group_name, output_dir, bottleneck_size):\n",
        "    \"\"\"使用訓練好的模型壓縮資料並保存為時間序列格式（只壓縮測試年）\"\"\"\n",
        "    compressed_dir = os.path.join(output_dir, \"compressed_data\")\n",
        "    os.makedirs(compressed_dir, exist_ok=True)\n",
        "\n",
        "    print(\"   準備壓縮資料...\")\n",
        "    all_data = prepare_indicator_data(df_to_compress, indicator_cols)\n",
        "\n",
        "    all_data_scaled = scaler.transform(all_data)\n",
        "\n",
        "    encoder_input = model.input\n",
        "    encoder_output = None\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if layer.name == 'bottleneck':\n",
        "            encoder_output = layer.output\n",
        "            break\n",
        "\n",
        "    if encoder_output is None:\n",
        "        bottleneck_layer_idx = None\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            if layer.name == 'bottleneck':\n",
        "                bottleneck_layer_idx = i\n",
        "                break\n",
        "\n",
        "        if bottleneck_layer_idx is not None:\n",
        "            encoder_output = model.layers[bottleneck_layer_idx].output\n",
        "        else:\n",
        "            raise ValueError(\"無法找到編碼器輸出層\")\n",
        "\n",
        "    encoder_model = models.Model(inputs=encoder_input, outputs=encoder_output)\n",
        "\n",
        "    print(\"   使用編碼器壓縮資料...\")\n",
        "    compressed_data = encoder_model.predict(all_data_scaled, verbose=0)\n",
        "\n",
        "    compressed_df = pd.DataFrame(\n",
        "        compressed_data,\n",
        "        columns=[f\"{group_name}_compressed_{i}\" for i in range(bottleneck_size)]\n",
        "    )\n",
        "\n",
        "    if 'datetime' in df_to_compress.columns:\n",
        "        compressed_df['datetime'] = df_to_compress['datetime'].values\n",
        "        cols = ['datetime'] + [col for col in compressed_df.columns if col != 'datetime']\n",
        "        compressed_df = compressed_df[cols]\n",
        "\n",
        "    output_path = os.path.join(compressed_dir, f\"{group_name}_compressed.csv\")\n",
        "    compressed_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    original_size = all_data.shape[1]\n",
        "    compressed_size = bottleneck_size\n",
        "    compression_ratio = original_size / compressed_size\n",
        "\n",
        "    print(\"   ✅ 壓縮完成！\")\n",
        "    print(f\"   原始維度: {original_size}\")\n",
        "    print(f\"   壓縮後維度: {compressed_size}\")\n",
        "    print(f\"   壓縮比: {compression_ratio:.2f}:1\")\n",
        "    print(f\"   資料筆數: {len(compressed_df):,}\")\n",
        "    print(f\"   保存路徑: {output_path}\")\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# ==================== 繪圖函數 ====================\n",
        "def plot_training_history(history, group_name, output_path):\n",
        "    \"\"\"繪製訓練歷史（包含時間軸）\"\"\"\n",
        "    has_time = 'epoch_times' in history and len(history['epoch_times']) > 0\n",
        "\n",
        "    if has_time:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "        epoch_times = history['epoch_times']\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    axes[0].plot(history['loss'], label='Train MSE', linewidth=2)\n",
        "    axes[0].plot(history['val_loss'], label='Val MSE', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('MSE', fontsize=12)\n",
        "    axes[0].set_title(f'{group_name} - Training MSE (by Epoch)', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(fontsize=10)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].semilogy(history['loss'], label='Train MSE', linewidth=2)\n",
        "    axes[1].semilogy(history['val_loss'], label='Val MSE', linewidth=2)\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('MSE (log scale)', fontsize=12)\n",
        "    axes[1].set_title(f'{group_name} - Training MSE (Log Scale, by Epoch)', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend(fontsize=10)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    if has_time:\n",
        "        axes[2].plot(epoch_times, history['loss'], label='Train MSE', linewidth=2)\n",
        "        axes[2].plot(epoch_times, history['val_loss'], label='Val MSE', linewidth=2)\n",
        "        axes[2].set_xlabel('Training Time (seconds)', fontsize=12)\n",
        "        axes[2].set_ylabel('MSE', fontsize=12)\n",
        "        axes[2].set_title(f'{group_name} - Training MSE (by Time)\\nTotal: {history.get(\"total_time\", 0):.1f}s',\n",
        "                         fontsize=14, fontweight='bold')\n",
        "        axes[2].legend(fontsize=10)\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# ==================== Excel 輸出 ====================\n",
        "def save_results_to_excel(all_results, output_dir):\n",
        "    \"\"\"將所有結果保存到 Excel\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"[SAVE] 保存結果到 Excel...\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    excel_path = os.path.join(output_dir, f\"autoencoder_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\")\n",
        "\n",
        "    wb = openpyxl.Workbook()\n",
        "\n",
        "    ws_summary = wb.active\n",
        "    ws_summary.title = \"摘要\"\n",
        "    ws_summary.append([\"視窗(訓練+測試)\", \"技術指標群組\", \"輸入維度\", \"最佳 Bottleneck\", \"最佳 LR\", \"最佳 Dropout\",\n",
        "                      \"最佳 Batch Size\", \"Train MSE\", \"Val MSE\", \"Train+Val MSE\", \"Test MSE\",\n",
        "                      \"訓練時間(秒)\", \"總訓練時間(秒)\"])\n",
        "\n",
        "    for result in all_results:\n",
        "        config = result['best_config']\n",
        "        final_scores = result['final_scores']\n",
        "\n",
        "        final_history = final_scores.get('history', {})\n",
        "        final_time = final_history.get('total_time', 0) if 'total_time' in final_history else 0\n",
        "\n",
        "        search_total_time = 0\n",
        "        for search_result in result.get('search_results', []):\n",
        "            if isinstance(search_result, dict) and 'history' in search_result:\n",
        "                search_total_time += search_result['history'].get('total_time', 0)\n",
        "\n",
        "        total_training_time = search_total_time + final_time\n",
        "\n",
        "        ws_summary.append([\n",
        "            result['window'],\n",
        "            result['group_name'],\n",
        "            result['input_dim'],\n",
        "            config['bottleneck'],\n",
        "            config['lr'],\n",
        "            config['dropout'],\n",
        "            config['batch'],\n",
        "            f\"{final_scores['train_mse']:.6f}\",\n",
        "            f\"{final_scores['val_mse']:.6f}\",\n",
        "            f\"{final_scores.get('train_val_mse', final_scores['train_mse']):.6f}\",\n",
        "            f\"{final_scores['test_mse']:.6f}\",\n",
        "            f\"{final_time:.2f}\",\n",
        "            f\"{total_training_time:.2f}\"\n",
        "        ])\n",
        "\n",
        "    existing_sheet_names = set([\"摘要\"])\n",
        "\n",
        "    def safe_sheet_name(name, existing_names):\n",
        "        base = name[:31]\n",
        "        if base not in existing_names:\n",
        "            existing_names.add(base)\n",
        "            return base\n",
        "        idx = 1\n",
        "        while True:\n",
        "            suffix = f\"_{idx}\"\n",
        "            trimmed = base[:31 - len(suffix)] + suffix\n",
        "            if trimmed not in existing_names:\n",
        "                existing_names.add(trimmed)\n",
        "                return trimmed\n",
        "            idx += 1\n",
        "\n",
        "    for result in all_results:\n",
        "        window = result['window']\n",
        "        group_name = result['group_name']\n",
        "        sheet_name = safe_sheet_name(f\"{window}_{group_name}\", existing_sheet_names)\n",
        "        ws = wb.create_sheet(title=sheet_name)\n",
        "\n",
        "        ws.append([\"超參數搜尋結果\"])\n",
        "        ws.append([\"Bottleneck\", \"Learning Rate\", \"Dropout\", \"Batch Size\", \"Train MSE\", \"Val MSE\"])\n",
        "\n",
        "        for search_result in result['search_results']:\n",
        "            config = search_result['config']\n",
        "            ws.append([\n",
        "                config['bottleneck'],\n",
        "                config['lr'],\n",
        "                config['dropout'],\n",
        "                config['batch'],\n",
        "                f\"{search_result['train_mse']:.6f}\",\n",
        "                f\"{search_result['val_mse']:.6f}\"\n",
        "            ])\n",
        "\n",
        "        ws.append([])\n",
        "        ws.append([\"最佳配置\"])\n",
        "        best_config = result['best_config']\n",
        "        ws.append([\"Bottleneck\", best_config['bottleneck']])\n",
        "        ws.append([\"Learning Rate\", best_config['lr']])\n",
        "        ws.append([\"Dropout\", best_config['dropout']])\n",
        "        ws.append([\"Batch Size\", best_config['batch']])\n",
        "\n",
        "        ws.append([])\n",
        "        ws.append([\"最終評估結果\"])\n",
        "        final_scores = result['final_scores']\n",
        "        ws.append([\"Train MSE\", f\"{final_scores['train_mse']:.6f}\"])\n",
        "        ws.append([\"Val MSE\", f\"{final_scores['val_mse']:.6f}\"])\n",
        "        if 'train_val_mse' in final_scores:\n",
        "            ws.append([\"Train+Val MSE\", f\"{final_scores['train_val_mse']:.6f}\"])\n",
        "        ws.append([\"Test MSE\", f\"{final_scores['test_mse']:.6f}\"])\n",
        "\n",
        "        ws.append([])\n",
        "        ws.append([\"訓練時間信息\"])\n",
        "        final_history = final_scores.get('history', {})\n",
        "        if 'total_time' in final_history:\n",
        "            ws.append([\"最終訓練時間\", f\"{final_history['total_time']:.2f} 秒\"])\n",
        "            ws.append([\"平均每 Epoch 時間\", f\"{final_history['total_time'] / max(len(final_history.get('loss', [])), 1):.2f} 秒\"])\n",
        "        else:\n",
        "            ws.append([\"最終訓練時間\", \"未記錄\"])\n",
        "\n",
        "        search_total_time = 0\n",
        "        for search_result in result.get('search_results', []):\n",
        "            if 'history' in search_result and 'total_time' in search_result['history']:\n",
        "                search_total_time += search_result['history']['total_time']\n",
        "        if search_total_time > 0:\n",
        "            ws.append([\"超參數搜尋總時間\", f\"{search_total_time:.2f} 秒\"])\n",
        "            ws.append([\"總訓練時間\", f\"{search_total_time + final_history.get('total_time', 0):.2f} 秒\"])\n",
        "\n",
        "        img_path = result['plot_path']\n",
        "        if os.path.exists(img_path):\n",
        "            try:\n",
        "                img = Image(img_path)\n",
        "                img.width = 800\n",
        "                img.height = 300\n",
        "                ws.add_image(img, f'A{ws.max_row + 3}')\n",
        "            except Exception as e:\n",
        "                print(f\"  [WARN] 無法插入圖片 {img_path}: {e}\")\n",
        "\n",
        "    ws_log = wb.create_sheet(title=\"訓練日誌\")\n",
        "    ws_log.append([\"時間\", \"視窗\", \"群組\", \"階段\", \"訊息\"])\n",
        "\n",
        "    for result in all_results:\n",
        "        if 'log' in result:\n",
        "            for log_entry in result['log']:\n",
        "                ws_log.append(log_entry)\n",
        "\n",
        "    wb.save(excel_path)\n",
        "    print(f\"[OK] Excel 已保存: {excel_path}\")\n",
        "\n",
        "    return excel_path\n",
        "\n",
        "# ==================== 主程式 ====================\n",
        "def main():\n",
        "    \"\"\"主程式\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"[START] 技術指標 Autoencoder 壓縮訓練\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"[TIME] 開始時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"[SEED] 隨機種子: {RANDOM_SEED}\")\n",
        "\n",
        "    print(\"\\n[GPU] GPU 檢查和配置...\")\n",
        "    print(f\"TensorFlow 版本: {tf.__version__}\")\n",
        "    print(f\"TensorFlow 是否構建時包含 CUDA 支持: {tf.test.is_built_with_cuda()}\")\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    print(f\"可用 GPU 清單: {gpus}\")\n",
        "\n",
        "    if len(gpus) > 0:\n",
        "        print(f\"✅ 檢測到 {len(gpus)} 個 GPU 設備\")\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            print(\"✅ GPU 記憶體增長已啟用\")\n",
        "\n",
        "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "            if len(logical_gpus) > 0:\n",
        "                print(f\"✅ GPU 可用於 TensorFlow 運算: {logical_gpus}\")\n",
        "                try:\n",
        "                    with tf.device('/GPU:0'):\n",
        "                        test_tensor = tf.constant([1.0, 2.0, 3.0])\n",
        "                        result = tf.reduce_sum(test_tensor)\n",
        "                    print(f\"✅ GPU 運算測試成功: {result.numpy()}\")\n",
        "                    print(\"TensorFlow 是否使用 GPU: True\")\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ GPU 運算測試失敗: {e}\")\n",
        "                    print(\"TensorFlow 是否使用 GPU: False\")\n",
        "            else:\n",
        "                print(\"❌ GPU 不可用於 TensorFlow 運算\")\n",
        "                print(\"TensorFlow 是否使用 GPU: False\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"⚠️ GPU 設定警告: {e}\")\n",
        "            print(\"TensorFlow 是否使用 GPU: False\")\n",
        "    else:\n",
        "        print(\"❌ 沒有檢測到 GPU 設備\")\n",
        "        if not tf.test.is_built_with_cuda():\n",
        "            print(\"⚠️ TensorFlow 當前版本似乎不包含 CUDA 支持（CPU-only 構建）\")\n",
        "            print(\"💡 提示：如果已安裝 CUDA，可能需要：\")\n",
        "            print(\"   1. 確保已安裝完整的 CUDA Toolkit（不僅是驅動）\")\n",
        "            print(\"   2. 安裝對應版本的 cuDNN\")\n",
        "            print(\"   3. 或考慮使用 conda 安裝支持 GPU 的 TensorFlow\")\n",
        "        print(\"將使用 CPU 進行運算\")\n",
        "        print(\"TensorFlow 是否使用 GPU: False\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    windows = build_rolling_windows_by_year(df, window_years=3)\n",
        "    print(f\"[INFO] 共找到 {len(windows)} 個 3 年滾動視窗\")\n",
        "\n",
        "    all_results = []\n",
        "    overall_start_time = datetime.now()\n",
        "\n",
        "    for window_idx, window_years in enumerate(windows, 1):\n",
        "        train_years = window_years[:2]\n",
        "        test_year = window_years[2]\n",
        "        window_label = f\"{train_years[0]}-{test_year}\"\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"[WINDOW {window_idx}/{len(windows)}] 3 年視窗: {window_label}\")\n",
        "        print(f\"   訓練年: {train_years[0]}, {train_years[1]}\")\n",
        "        print(f\"   測試年: {test_year}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        window_output_dir = os.path.join(OUTPUT_DIR, f\"window_{window_label}\")\n",
        "        models_dir = os.path.join(window_output_dir, \"models\")\n",
        "        plots_dir = os.path.join(window_output_dir, \"plots\")\n",
        "        os.makedirs(models_dir, exist_ok=True)\n",
        "        os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "        train_pool_df = df[df['datetime'].dt.year.isin(train_years)].copy()\n",
        "        test_df = df[df['datetime'].dt.year == test_year].copy()\n",
        "\n",
        "        if train_pool_df.empty or test_df.empty:\n",
        "            print(\"[WARN] 當前視窗資料不足，跳過。\")\n",
        "            continue\n",
        "\n",
        "        train_df, val_df = split_train_val_by_date(train_pool_df, VAL_SPLIT)\n",
        "\n",
        "        total_groups = len(INDICATOR_GROUPS)\n",
        "        for group_idx, (group_name, indicator_cols) in enumerate(INDICATOR_GROUPS.items(), 1):\n",
        "            print(f\"\\n{'#'*60}\")\n",
        "            print(f\"[GROUP {group_idx}/{total_groups}] 視窗 {window_label} | 群組: {group_name}\")\n",
        "            print(f\"   包含指標: {', '.join(indicator_cols)}\")\n",
        "            print(f\"   群組進度: {group_idx}/{total_groups} ({group_idx/total_groups*100:.1f}%)\")\n",
        "\n",
        "            elapsed = (datetime.now() - overall_start_time).total_seconds()\n",
        "            if group_idx > 1:\n",
        "                avg_time_per_group = elapsed / (group_idx - 1)\n",
        "                remaining_groups = total_groups - group_idx + 1\n",
        "                remaining_time = avg_time_per_group * remaining_groups\n",
        "                print(f\"   已用時間: {elapsed:.1f}秒 | 預計剩餘: {remaining_time:.1f}秒\")\n",
        "\n",
        "            try:\n",
        "                X_train_raw = prepare_indicator_data(train_df, indicator_cols)\n",
        "                X_val_raw = prepare_indicator_data(val_df, indicator_cols)\n",
        "                X_test_raw = prepare_indicator_data(test_df, indicator_cols)\n",
        "\n",
        "                scaler = StandardScaler()\n",
        "                X_train = scaler.fit_transform(X_train_raw)\n",
        "                X_val = scaler.transform(X_val_raw)\n",
        "                X_test = scaler.transform(X_test_raw)\n",
        "\n",
        "                print(\"[OK] 資料準備完成\")\n",
        "                print(f\"   訓練集形狀: {X_train.shape}\")\n",
        "                print(f\"   驗證集形狀: {X_val.shape}\")\n",
        "                print(f\"   測試集形狀: {X_test.shape}\")\n",
        "\n",
        "                best_model, best_config, best_history, search_results = hyperparameter_search(\n",
        "                    X_train, X_val, group_name, indicator_cols\n",
        "                )\n",
        "\n",
        "                search_model_path = os.path.join(models_dir, f\"{group_name}_search_best.h5\")\n",
        "                best_model.save(search_model_path)\n",
        "\n",
        "                if SKIP_FINAL_TRAINING:\n",
        "                    print(\"\\n[OPTIMIZE] 跳過最終訓練，直接使用搜索階段最佳模型\")\n",
        "                    final_model = best_model\n",
        "                    final_history = best_history\n",
        "\n",
        "                    print(\"   [評估中...] \", end='', flush=True)\n",
        "                    X_train_val = np.vstack([X_train, X_val])\n",
        "\n",
        "                    train_val_pred = final_model.predict(X_train_val, verbose=0)\n",
        "                    test_pred = final_model.predict(X_test, verbose=0)\n",
        "\n",
        "                    train_val_mse = mean_squared_error(X_train_val, train_val_pred)\n",
        "                    test_mse = mean_squared_error(X_test, test_pred)\n",
        "\n",
        "                    train_pred_only = final_model.predict(X_train, verbose=0)\n",
        "                    val_pred_only = final_model.predict(X_val, verbose=0)\n",
        "                    train_mse = mean_squared_error(X_train, train_pred_only)\n",
        "                    val_mse = mean_squared_error(X_val, val_pred_only)\n",
        "\n",
        "                    print(\"[完成]\")\n",
        "                    print(f\"   [結果] Train MSE: {train_mse:.6f}\")\n",
        "                    print(f\"   [結果] Val MSE: {val_mse:.6f}\")\n",
        "                    print(f\"   [結果] Train+Val MSE: {train_val_mse:.6f}\")\n",
        "                    print(f\"   [結果] Test MSE: {test_mse:.6f}\")\n",
        "\n",
        "                    final_scores = {\n",
        "                        'train_mse': train_mse,\n",
        "                        'val_mse': val_mse,\n",
        "                        'train_val_mse': train_val_mse,\n",
        "                        'test_mse': test_mse,\n",
        "                        'history': final_history\n",
        "                    }\n",
        "\n",
        "                    final_model_path = search_model_path\n",
        "                else:\n",
        "                    final_model, final_scores = final_training(\n",
        "                        X_train, X_val, X_test, best_config, group_name, best_model=best_model\n",
        "                    )\n",
        "\n",
        "                    final_model_path = os.path.join(models_dir, f\"{group_name}_final.h5\")\n",
        "                    final_model.save(final_model_path)\n",
        "\n",
        "                plot_path = os.path.join(plots_dir, f\"{group_name}_training_history.png\")\n",
        "                plot_training_history(final_scores['history'], group_name, plot_path)\n",
        "\n",
        "                scaler_path = os.path.join(models_dir, f\"{group_name}_scaler.pkl\")\n",
        "                import pickle\n",
        "                with open(scaler_path, 'wb') as f:\n",
        "                    pickle.dump(scaler, f)\n",
        "\n",
        "                print(f\"\\n[COMPRESS] 壓縮測試年資料: {group_name} | 視窗 {window_label}\")\n",
        "                compressed_data_path = compress_and_save_data(\n",
        "                    final_model, scaler, test_df, indicator_cols, group_name,\n",
        "                    window_output_dir, best_config['bottleneck']\n",
        "                )\n",
        "\n",
        "                all_results.append({\n",
        "                    'window': window_label,\n",
        "                    'group_name': group_name,\n",
        "                    'input_dim': len(indicator_cols),\n",
        "                    'best_config': best_config,\n",
        "                    'search_results': [\n",
        "                        {\n",
        "                            'config': r['config'],\n",
        "                            'train_mse': r['train_mse'],\n",
        "                            'val_mse': r['val_mse'],\n",
        "                            'history': r.get('history', {})\n",
        "                        }\n",
        "                        for r in search_results\n",
        "                    ],\n",
        "                    'final_scores': final_scores,\n",
        "                    'plot_path': plot_path,\n",
        "                    'model_path': final_model_path,\n",
        "                    'scaler_path': scaler_path,\n",
        "                    'compressed_data_path': compressed_data_path\n",
        "                })\n",
        "\n",
        "                print(f\"[OK] {group_name} 視窗 {window_label} 處理完成\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[ERROR] {group_name} 視窗 {window_label} 處理失敗: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "    excel_path = save_results_to_excel(all_results, OUTPUT_DIR)\n",
        "\n",
        "    json_path = os.path.join(OUTPUT_DIR, f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
        "    json_results = []\n",
        "    for r in all_results:\n",
        "        json_results.append({\n",
        "            'window': r['window'],\n",
        "            'group_name': r['group_name'],\n",
        "            'input_dim': r['input_dim'],\n",
        "            'best_config': r['best_config'],\n",
        "            'final_scores': r['final_scores'],\n",
        "            'search_results': r['search_results']\n",
        "        })\n",
        "\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(json_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"[DONE] 所有處理完成！\")\n",
        "    print(f\"[DIR] 結果目錄: {OUTPUT_DIR}\")\n",
        "    print(f\"[EXCEL] Excel 報告: {excel_path}\")\n",
        "    print(f\"[JSON] JSON 報告: {json_path}\")\n",
        "\n",
        "    print(f\"[TIME] 結束時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "[START] 技術指標 Autoencoder 壓縮訓練\n",
            "============================================================\n",
            "[TIME] 開始時間: 2026-02-08 15:56:59\n",
            "[SEED] 隨機種子: 42\n",
            "\n",
            "[GPU] GPU 檢查和配置...\n",
            "TensorFlow 版本: 2.19.0\n",
            "TensorFlow 是否構建時包含 CUDA 支持: True\n",
            "可用 GPU 清單: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "✅ 檢測到 1 個 GPU 設備\n",
            "✅ GPU 記憶體增長已啟用\n",
            "✅ GPU 可用於 TensorFlow 運算: [LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
            "✅ GPU 運算測試成功: 6.0\n",
            "TensorFlow 是否使用 GPU: True\n",
            "\n",
            "============================================================\n",
            "[INFO] 改用「交易日」切分資料 (總天數: 2723 天)\n",
            "  訓練集天數: 1907\n",
            "  驗證集天數: 544\n",
            "  測試集天數: 272\n",
            "  Cutoff 1 (Train|Val): 2020-02-24\n",
            "  Cutoff 2 (Val|Test) : 2022-09-30\n",
            "------------------------------------------------------------\n",
            "  訓練集: 574,007 筆 (70.0%) | 時間: 2011-01-03 08:45:00 至 2020-02-21 13:45:00\n",
            "  驗證集: 163,744 筆 (20.0%) | 時間: 2020-02-24 08:45:00 至 2022-09-29 13:45:00\n",
            "  測試集: 81,872 筆 (10.0%) | 時間: 2022-09-30 08:45:00 至 2023-12-22 13:45:00\n",
            "\n",
            "############################################################\n",
            "[GROUP 1/7] 處理技術指標群組: STOCH\n",
            "   包含指標: STOCH_K_14, STOCH_D_14\n",
            "   總體進度: 1/7 (14.3%)\n",
            "############################################################\n",
            "[OK] 資料準備完成\n",
            "   訓練集形狀: (574007, 2)\n",
            "   驗證集形狀: (163744, 2)\n",
            "   測試集形狀: (81872, 2)\n",
            "\n",
            "============================================================\n",
            "[SEARCH] 開始貝葉斯優化超參數搜尋: STOCH\n",
            "   輸入維度: 2\n",
            "   優化迭代次數: 24\n",
            "   Bottleneck 固定為: 1（將 2 維壓縮為 1 維）\n",
            "\n",
            "[INFO] 開始貝葉斯優化（高斯過程）...\n",
            "\n",
            "  [貝葉斯優化 0.0%] [1/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 1e-03, Dropout: 0.05, Batch: 32786\n",
            "    [訓練中...] [完成] 訓練時間: 37.76秒 (60 epochs)\n",
            "    [結果] 最佳 Val Loss: 1.137341\n",
            "[評估中...] [完成] Train MSE: 1.000001, Val MSE: 1.137341\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 4.2%] [2/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 1e-03, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 79.2秒 | 預計剩餘: 1820.8秒\n",
            "    [訓練中...] [完成] 訓練時間: 12.73秒 (13 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.032367\n",
            "[評估中...] [完成] Train MSE: 0.029700, Val MSE: 0.032368\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 8.3%] [3/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 127.8秒 | 預計剩餘: 1405.4秒\n",
            "    [訓練中...] [完成] 訓練時間: 42.31秒 (56 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.024949\n",
            "[評估中...] [完成] Train MSE: 0.024360, Val MSE: 0.024949\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 12.5%] [4/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.1, Batch: 32786\n",
            "    已用時間: 206.1秒 | 預計剩餘: 1443.0秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.14秒 (23 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.027283\n",
            "\n",
            "  [貝葉斯優化 16.7%] [5/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 1e-03, Dropout: 0.3, Batch: 32786\n",
            "    已用時間: 220.4秒 | 預計剩餘: 1102.1秒\n",
            "    [訓練中...] [完成] 訓練時間: 12.16秒 (12 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.041456\n",
            "\n",
            "  [貝葉斯優化 20.8%] [6/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.3, Batch: 32786\n",
            "    已用時間: 232.8秒 | 預計剩餘: 884.7秒\n",
            "    [訓練中...] [完成] 訓練時間: 13.73秒 (21 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.057214\n",
            "\n",
            "  [貝葉斯優化 25.0%] [7/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 4e-04, Dropout: 0.4, Batch: 32786\n",
            "    已用時間: 246.8秒 | 預計剩餘: 740.4秒\n",
            "    [訓練中...] [完成] 訓練時間: 33.62秒 (128 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.313382\n",
            "\n",
            "  [貝葉斯優化 29.2%] [8/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 3e-04, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 280.7秒 | 預計剩餘: 681.6秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.63秒 (26 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.034788\n",
            "\n",
            "  [貝葉斯優化 33.3%] [9/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 2e-03, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 295.5秒 | 預計剩餘: 591.1秒\n",
            "    [訓練中...] [完成] 訓練時間: 10.35秒 (9 epochs)\n",
            "    [結果] 最佳 Val Loss: 1.137263\n",
            "\n",
            "  [貝葉斯優化 37.5%] [10/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.05, Batch: 32786\n",
            "    已用時間: 306.1秒 | 預計剩餘: 510.2秒\n",
            "    [訓練中...] [完成] 訓練時間: 15.37秒 (30 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.026330\n",
            "\n",
            "  [貝葉斯優化 41.7%] [11/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 9e-04, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 321.8秒 | 預計剩餘: 450.5秒\n",
            "    [訓練中...] [完成] 訓練時間: 12.98秒 (17 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.038692\n",
            "\n",
            "  [貝葉斯優化 45.8%] [12/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 335.0秒 | 預計剩餘: 396.0秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.05秒 (23 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.043025\n",
            "\n",
            "  [貝葉斯優化 50.0%] [13/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 349.3秒 | 預計剩餘: 349.3秒\n",
            "    [訓練中...] [完成] 訓練時間: 10.54秒 (10 epochs)\n",
            "    [結果] 最佳 Val Loss: 1.137333\n",
            "\n",
            "  [貝葉斯優化 54.2%] [14/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 3e-04, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 360.1秒 | 預計剩餘: 304.7秒\n",
            "    [訓練中...] [完成] 訓練時間: 15.46秒 (28 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.035325\n",
            "\n",
            "  [貝葉斯優化 58.3%] [15/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 8e-04, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 375.8秒 | 預計剩餘: 268.4秒\n",
            "    [訓練中...] [完成] 訓練時間: 16.45秒 (45 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.024952\n",
            "[評估中...] [完成] Train MSE: 0.024359, Val MSE: 0.024952\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 62.5%] [16/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.1, Batch: 32786\n",
            "    已用時間: 428.1秒 | 預計剩餘: 256.8秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.10秒 (23 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.029700\n",
            "\n",
            "  [貝葉斯優化 66.7%] [17/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 442.4秒 | 預計剩餘: 221.2秒\n",
            "    [訓練中...] [完成] 訓練時間: 13.37秒 (19 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.035360\n",
            "\n",
            "  [貝葉斯優化 70.8%] [18/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 4e-04, Dropout: 0.05, Batch: 32786\n",
            "    已用時間: 456.1秒 | 預計剩餘: 187.8秒\n",
            "    [訓練中...] [完成] 訓練時間: 11.94秒 (11 epochs)\n",
            "    [結果] 最佳 Val Loss: 1.137312\n",
            "\n",
            "  [貝葉斯優化 75.0%] [19/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.4, Batch: 32786\n",
            "    已用時間: 468.3秒 | 預計剩餘: 156.1秒\n",
            "    [訓練中...] [完成] 訓練時間: 13.17秒 (18 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.053698\n",
            "\n",
            "  [貝葉斯優化 79.2%] [20/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 481.7秒 | 預計剩餘: 126.8秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.28秒 (24 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.039495\n",
            "\n",
            "  [貝葉斯優化 83.3%] [21/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 8e-04, Dropout: 0.1, Batch: 32786\n",
            "    已用時間: 496.8秒 | 預計剩餘: 99.4秒\n",
            "    [訓練中...] [完成] 訓練時間: 11.62秒 (9 epochs)\n",
            "    [結果] 最佳 Val Loss: 1.137324\n",
            "\n",
            "  [貝葉斯優化 87.5%] [22/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.1, Batch: 32786\n",
            "    已用時間: 508.7秒 | 預計剩餘: 72.7秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.23秒 (24 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.027705\n",
            "\n",
            "  [貝葉斯優化 91.7%] [23/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 8e-04, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 523.2秒 | 預計剩餘: 47.6秒\n",
            "    [訓練中...] [完成] 訓練時間: 15.62秒 (40 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.024956\n",
            "[評估中...] [完成] Train MSE: 0.024371, Val MSE: 0.024955\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 95.8%] [24/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.1, Batch: 32786\n",
            "    已用時間: 575.1秒 | 預計剩餘: 25.0秒\n",
            "    [訓練中...] [完成] 訓練時間: 13.85秒 (22 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.028083\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[BEST] 最佳超參數 (STOCH):\n",
            "   Bottleneck: 1 (固定)\n",
            "   Learning Rate: 8e-04\n",
            "   Dropout: 0.0\n",
            "   Batch Size: 32786\n",
            "   最佳驗證損失: 0.024956\n",
            "   驗證集 MSE: 0.024955\n",
            "\n",
            "[INFO] 貝葉斯優化找到的最佳目標值: 0.024949\n",
            "[INFO] 最佳參數位置: [0.0006989510422011376, np.int64(0)]\n",
            "\n",
            "[OPTIMIZE] 跳過最終訓練，直接使用搜索階段最佳模型（節省時間）\n",
            "   [評估中...] [完成]\n",
            "   [結果] Train MSE: 0.024371\n",
            "   [結果] Val MSE: 0.024955\n",
            "   [結果] Train+Val MSE: 0.024500\n",
            "   [結果] Test MSE: 0.026518\n",
            "\n",
            "[COMPRESS] 開始壓縮時間序列資料: STOCH\n",
            "   準備壓縮資料...\n",
            "   使用編碼器壓縮資料...\n",
            "   ✅ 壓縮完成！\n",
            "   原始維度: 2\n",
            "   壓縮後維度: 1\n",
            "   壓縮比: 2.00:1\n",
            "   資料筆數: 819,623\n",
            "   保存路徑: /content/drive/MyDrive/工作區/論文/論文code/1106/output2/compressed_data/STOCH_compressed.csv\n",
            "[OK] STOCH 處理完成！ (耗時: 719.8秒)\n",
            "   已完成 1/7 個群組 (14.3%)\n",
            "\n",
            "############################################################\n",
            "[GROUP 2/7] 處理技術指標群組: STOCHF\n",
            "   包含指標: STOCHF_K_14, STOCHF_D_14\n",
            "   總體進度: 2/7 (28.6%)\n",
            "   已用時間: 719.8秒 | 預計剩餘: 4318.7秒 (72.0分鐘)\n",
            "############################################################\n",
            "[OK] 資料準備完成\n",
            "   訓練集形狀: (574007, 2)\n",
            "   驗證集形狀: (163744, 2)\n",
            "   測試集形狀: (81872, 2)\n",
            "\n",
            "============================================================\n",
            "[SEARCH] 開始貝葉斯優化超參數搜尋: STOCHF\n",
            "   輸入維度: 2\n",
            "   優化迭代次數: 24\n",
            "   Bottleneck 固定為: 1（將 2 維壓縮為 1 維）\n",
            "\n",
            "[INFO] 開始貝葉斯優化（高斯過程）...\n",
            "\n",
            "  [貝葉斯優化 0.0%] [1/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 1e-03, Dropout: 0.05, Batch: 32786\n",
            "    [訓練中...] [完成] 訓練時間: 13.88秒 (21 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.051182\n",
            "[評估中...] [完成] Train MSE: 0.052306, Val MSE: 0.051184\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 4.2%] [2/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 1e-03, Dropout: 0.2, Batch: 32786\n",
            "    已用時間: 49.8秒 | 預計剩餘: 1145.1秒\n",
            "    [訓練中...] [完成] 訓練時間: 12.64秒 (15 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.055913\n",
            "\n",
            "  [貝葉斯優化 8.3%] [3/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 62.5秒 | 預計剩餘: 687.2秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.44秒 (33 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.050369\n",
            "[評估中...] [完成] Train MSE: 0.051606, Val MSE: 0.050369\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 12.5%] [4/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.1, Batch: 32786\n",
            "    已用時間: 112.5秒 | 預計剩餘: 787.4秒\n",
            "    [訓練中...] [完成] 訓練時間: 13.20秒 (18 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.053453\n",
            "\n",
            "  [貝葉斯優化 16.7%] [5/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 3e-04, Dropout: 0.4, Batch: 32786\n",
            "    已用時間: 125.9秒 | 預計剩餘: 629.3秒\n",
            "    [訓練中...] [完成] 訓練時間: 15.90秒 (33 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.116054\n",
            "\n",
            "  [貝葉斯優化 20.8%] [6/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 2e-03, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 142.0秒 | 預計剩餘: 539.4秒\n",
            "    [訓練中...] [完成] 訓練時間: 10.56秒 (10 epochs)\n",
            "    [結果] 最佳 Val Loss: 1.117315\n",
            "\n",
            "  [貝葉斯優化 25.0%] [7/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 5e-04, Dropout: 0.3, Batch: 32786\n",
            "    已用時間: 152.7秒 | 預計剩餘: 458.2秒\n",
            "    [訓練中...] [完成] 訓練時間: 14.04秒 (23 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.068602\n",
            "\n",
            "  [貝葉斯優化 29.2%] [8/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 4e-04, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 167.0秒 | 預計剩餘: 405.6秒\n",
            "    [訓練中...] [完成] 訓練時間: 20.88秒 (66 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.050268\n",
            "[評估中...] [完成] Train MSE: 0.051546, Val MSE: 0.050268\n",
            "    [BEST] 更新最佳模型！\n",
            "\n",
            "  [貝葉斯優化 33.3%] [9/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.4, Batch: 32786\n",
            "    已用時間: 223.7秒 | 預計剩餘: 447.5秒\n",
            "    [訓練中...] [完成] 訓練時間: 13.53秒 (20 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.094724\n",
            "\n",
            "  [貝葉斯優化 37.5%] [10/24] 測試組合:\n",
            "    Bottleneck: 1, LR: 7e-04, Dropout: 0.0, Batch: 32786\n",
            "    已用時間: 237.5秒 | 預計剩餘: 395.8秒\n",
            "    [訓練中...] [完成] 訓練時間: 19.42秒 (63 epochs)\n",
            "    [結果] 最佳 Val Loss: 0.050205\n",
            "[評估中...] "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}