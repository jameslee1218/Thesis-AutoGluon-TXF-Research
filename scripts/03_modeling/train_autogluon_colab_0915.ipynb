{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Y4IBghCHgk"
      },
      "source": [
        "# AutoGluon æ»¾å‹•è¨“ç·´ â€” æˆªé» 0915ï¼ˆè¨“ç·´å¹´ 2,3,4,5 æ¯”è¼ƒï¼‰\n",
        "\n",
        "- **è¼¸å…¥**ï¼š`data/autogluon_ready/0915/merged_for_autogluon_0915.csv`\n",
        "- **æµç¨‹**ï¼šè¿´åœˆ train_years=2,3,4,5ï¼Œå„ã€ŒNå¹´è¨“ç·´â†’é æ¸¬ç¬¬N+1å¹´ã€\n",
        "- **è¼¸å‡º**ï¼š`data/models/0915/train{N}y/roll_YYYY/`ï¼Œå«æ‰€æœ‰æ¨¡å‹ç´€éŒ„\n",
        "- **æ–·ç·šçºŒè·‘**ï¼šè‹¥ `predictions.csv` å·²å­˜åœ¨å‰‡è·³é\n",
        "- **ä¸¦è¡Œ**ï¼šå¯åŒæ™‚é–‹ä¸‰å€‹ Colab åˆ†åˆ¥è·‘ 0900ã€0915ã€0930\n",
        "- **Colab**ï¼šæ›è¼‰ Drive å¾Œè¨­å®š `DRIVE_PROJECT_ROOT`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3I6AI3pCHgm"
      },
      "source": [
        "## 1. æ›è¼‰ Google Driveï¼ˆColab å¿…è·‘ï¼›æœ¬æ©Ÿå¯ç•¥ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsnOGcy5CHgn",
        "outputId": "0a693cf1-67bf-4705-a37e-6af9b4a16184"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "print(\"Colab:\", IN_COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjGjh9cVCHgo"
      },
      "source": [
        "## 2. è·¯å¾‘èˆ‡åƒæ•¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yizqNL0cscZO",
        "outputId": "cdd066fa-b1b2-476b-8dbc-cc2fea90029a"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# ========== è¼¸å…¥ï¼è¼¸å‡ºè·¯å¾‘ï¼ˆç›´æ¥å¯«æ­»ï¼Œç•™ç©ºå‰‡ç”¨é è¨­ï¼‰ ==========\n",
        "MERGED_CSV_PATH = \"\"  # è¼¸å…¥ CSVï¼Œä¾‹: \"/content/drive/MyDrive/xxx/merged_for_autogluon_0915.csv\"\n",
        "OUTPUT_ROOT = \"\"     # è¼¸å‡ºç›®éŒ„ï¼Œä¾‹: \"/content/drive/MyDrive/xxx/models/0915\"\n",
        "\n",
        "# é è¨­è·¯å¾‘ï¼ˆMERGED_CSV_PATHã€OUTPUT_ROOT ç•™ç©ºæ™‚ä½¿ç”¨ï¼‰\n",
        "DRIVE_PROJECT_ROOT = \"/content/drive/MyDrive/Thesis-AutoGluon-TXF-Research\"\n",
        "LOCAL_PROJECT_ROOT = \"/Volumes/Transcend/thesis/github_clone/Thesis-AutoGluon-TXF-Research\"\n",
        "PROJECT_ROOT = Path(DRIVE_PROJECT_ROOT) if IN_COLAB else Path(LOCAL_PROJECT_ROOT)\n",
        "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
        "\n",
        "CUTOFF = \"0915\"\n",
        "TRAIN_YEARS_LIST = [2, 3, 4, 5]\n",
        "LABEL = \"target_return\"\n",
        "TIME_LIMIT = 3600\n",
        "\n",
        "merged_path = Path(MERGED_CSV_PATH) if MERGED_CSV_PATH else DATA_ROOT / \"autogluon_ready\" / CUTOFF / (\"merged_for_autogluon_\" + CUTOFF + \".csv\")\n",
        "output_root = Path(OUTPUT_ROOT) if OUTPUT_ROOT else DATA_ROOT / \"models\" / CUTOFF\n",
        "print(\"è¼¸å…¥:\", \"âœ…\" if merged_path.exists() else \"âŒ\", merged_path)\n",
        "print(\"è¼¸å‡º:\", output_root)\n",
        "print(\"CUTOFF:\", CUTOFF, \"| TRAIN_YEARS_LIST:\", TRAIN_YEARS_LIST)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNemA6jsCHgo",
        "outputId": "14601ee7-c0e6-4a94-901a-3d173f612034"
      },
      "outputs": [],
      "source": [
        "# è·¯å¾‘èˆ‡åƒæ•¸å·²åœ¨ä¸Šæ–¹ cell è¨­å®šï¼›æ­¤ cell å¯ç•¥éæˆ–åˆªé™¤\n",
        "# è‹¥éœ€æ”¹æˆªé»ï¼Œè«‹ä¿®æ”¹ä¸Šæ–¹ CUTOFF = \"0900\" | \"0915\" | \"0930\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwJIqJf4CHgp"
      },
      "source": [
        "## 3. å®‰è£ AutoGluonï¼ˆColab é€šå¸¸éœ€åŸ·è¡Œä¸€æ¬¡ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd4N28sOCHgp",
        "outputId": "23bff688-f4c1-4aff-9c4d-d43eed4a3f4e"
      },
      "outputs": [],
      "source": [
        "!pip3 install autogluon.tabular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8rB07Y5CHgp"
      },
      "source": [
        "## 4. è¼‰å…¥è³‡æ–™ï¼ˆå·²ç§»è‡³ä¸‹æ–¹è¨“ç·´ cellï¼Œä¾ cutoff åˆ†åˆ¥è¼‰å…¥ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCuP06qXCHgq",
        "outputId": "c26a801d-5e73-4f2c-de7a-38e51f6268ae"
      },
      "outputs": [],
      "source": [
        "# è³‡æ–™è¼‰å…¥å·²ç§»è‡³ä¸‹æ–¹ã€Œæ»¾å‹•è¨“ç·´ã€cellï¼Œä¾æ¯å€‹ cutoff åˆ†åˆ¥è¼‰å…¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gffkPpIQscZP"
      },
      "outputs": [],
      "source": [
        "# Sharpe å›æ¸¬ï¼ˆèˆ‡ working/1129 intraday_macro_features_test sharpe.ipynb ç›¸åŒé‚è¼¯ï¼‰\n",
        "COST_PER_TRADE = 0.0005\n",
        "TRADE_THRESHOLD = 0.0001\n",
        "\n",
        "def compute_sharpe_backtest(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    positions = np.zeros_like(y_pred, dtype=float)\n",
        "    positions[y_pred > TRADE_THRESHOLD] = 1.0\n",
        "    positions[y_pred < -TRADE_THRESHOLD] = -1.0\n",
        "    strategy_returns = positions * y_true\n",
        "    trades = np.sum(np.abs(np.diff(np.insert(positions, 0, 0))) > 0)\n",
        "    total_cost = trades * COST_PER_TRADE\n",
        "    mean_return_with_cost = (np.sum(strategy_returns) - total_cost) / max(len(strategy_returns), 1)\n",
        "    std_return = np.std(strategy_returns)\n",
        "    if std_return == 0:\n",
        "        return 0.0\n",
        "    return float(mean_return_with_cost / (std_return + 1e-9) * np.sqrt(252))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkB-0M57scZP"
      },
      "source": [
        "## 5. æ»¾å‹•è¨“ç·´ï¼šæˆªé» 0915ï¼Œtrain_years=2,3,4,5 è¿´åœˆï¼Œå·²å­˜åœ¨å‰‡è·³é\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gkCcaWNXCHgq",
        "outputId": "325762f3-3e2c-4140-bac8-f08aadec7f19"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# merged_pathã€output_root ç”±ä¸Šæ–¹è·¯å¾‘ cell è¨­å®š\n",
        "HAS_GPU = torch.cuda.is_available()\n",
        "print(f\"ç³»çµ±æª¢æŸ¥: GPU {'å¯ç”¨ âœ…' if HAS_GPU else 'æœªåµæ¸¬åˆ° âš ï¸ (å°‡ä½¿ç”¨ CPU)'}\")\n",
        "print(f\"è¨“ç·´è¨­å®š: æˆªé» {CUTOFF}, è¨“ç·´å¹´æ•¸={TRAIN_YEARS_LIST}, é™æ™‚={TIME_LIMIT}ç§’\")\n",
        "print(f\"æ–·ç·šçºŒè·‘: è‹¥ train{{N}}y/roll_YYYY å…§å·²æœ‰ predictions.csv å‰‡è·³é\\n\")\n",
        "\n",
        "cutoff = CUTOFF\n",
        "# merged_path ç”±ä¸Šæ–¹è·¯å¾‘ cell è¨­å®šï¼ˆå¯é€é MERGED_CSV_PATH ç›´æ¥æŒ‡å®šï¼‰\n",
        "if not merged_path.exists():\n",
        "    print(f\"âŒ æª”æ¡ˆä¸å­˜åœ¨: {merged_path}\")\n",
        "else:\n",
        "    df = pd.read_csv(merged_path)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"date\"]).drop(columns=[\"datetime\"], errors=\"ignore\")\n",
        "    df[\"year\"] = df[\"date\"].dt.year\n",
        "    df = df.dropna()\n",
        "    if LABEL not in df.columns:\n",
        "        print(f\"âŒ ç„¡ {LABEL} æ¬„ä½\")\n",
        "    else:\n",
        "        years = sorted(df[\"year\"].unique())\n",
        "        ROLL_OUTPUT = output_root  # ç”±ä¸Šæ–¹è·¯å¾‘ cell è¨­å®šï¼ˆå¯é€é OUTPUT_ROOT ç›´æ¥æŒ‡å®šï¼‰\n",
        "        ROLL_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
        "        all_summary = []\n",
        "        all_models_perf = []\n",
        "\n",
        "        for TRAIN_YEARS in TRAIN_YEARS_LIST:\n",
        "            predict_years = [y for y in years if all((y - i) in years for i in range(1, TRAIN_YEARS + 1))]\n",
        "            predict_years = sorted(set(predict_years))\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"# train{TRAIN_YEARS}y â†’ é æ¸¬å¹´: {predict_years}\")\n",
        "            print(f\"{'='*50}\")\n",
        "\n",
        "            train_out = ROLL_OUTPUT / f\"train{TRAIN_YEARS}y\"\n",
        "            train_out.mkdir(parents=True, exist_ok=True)\n",
        "            summary_list = []\n",
        "            per_year_reports = {}\n",
        "\n",
        "            for predict_year in predict_years:\n",
        "                required_train_years = range(predict_year - TRAIN_YEARS, predict_year)\n",
        "                path_roll = train_out / f\"roll_{predict_year}\"\n",
        "\n",
        "                if (path_roll / \"predictions.csv\").exists():\n",
        "                    print(f\"  â­ï¸ {predict_year}: å·²å­˜åœ¨ï¼Œè·³éè¨“ç·´\")\n",
        "                    try:\n",
        "                        with open(path_roll / \"metrics.json\") as f:\n",
        "                            m = json.load(f)\n",
        "                        summary_list.append({\n",
        "                            \"cutoff\": cutoff, \"train_years\": TRAIN_YEARS, \"predict_year\": int(predict_year),\n",
        "                            \"train_period\": m.get(\"train_period\", \"\"),\n",
        "                            \"rmse\": m.get(\"rmse\"), \"sharpe\": m.get(\"sharpe\"),\n",
        "                            \"best_model\": m.get(\"best_model\", \"\"), \"model_path\": f\"train{TRAIN_YEARS}y/roll_{predict_year}\", \"skipped\": True\n",
        "                        })\n",
        "                        lb = pd.read_csv(path_roll / \"leaderboard_with_metrics.csv\") if (path_roll / \"leaderboard_with_metrics.csv\").exists() else pd.DataFrame()\n",
        "                        perf = pd.read_csv(path_roll / \"models_performance.csv\") if (path_roll / \"models_performance.csv\").exists() else pd.DataFrame()\n",
        "                        fi = pd.read_csv(path_roll / \"feature_importance_all_models.csv\") if (path_roll / \"feature_importance_all_models.csv\").exists() else pd.DataFrame()\n",
        "                        per_year_reports[int(predict_year)] = {\"leaderboard\": lb, \"model_performance\": perf, \"feature_importance\": fi}\n",
        "                        if not perf.empty:\n",
        "                            perf[\"train_years\"] = TRAIN_YEARS\n",
        "                            perf[\"cutoff\"] = cutoff\n",
        "                            all_models_perf.append(perf)\n",
        "                    except Exception as e:\n",
        "                        print(f\"    âš ï¸ è¼‰å…¥æ—¢æœ‰çµæœå¤±æ•—: {e}\")\n",
        "                    continue\n",
        "\n",
        "                missing_years = [y for y in required_train_years if y not in df[\"year\"].unique()]\n",
        "                if missing_years:\n",
        "                    print(f\"  âŒ è·³é {predict_year}: ç¼ºå°‘ {missing_years}\")\n",
        "                    continue\n",
        "\n",
        "                train_df = df[df[\"year\"].isin(required_train_years)].copy()\n",
        "                test_df = df[df[\"year\"] == predict_year].copy()\n",
        "                train_ag = train_df.drop(columns=[\"date\", \"datetime\", \"year\"], errors=\"ignore\").dropna()\n",
        "                test_ag = test_df.drop(columns=[\"date\", \"datetime\", \"year\"], errors=\"ignore\").dropna()\n",
        "\n",
        "                if len(train_ag) < 50 or len(test_ag) < 10:\n",
        "                    print(f\"  âš ï¸ è·³é {predict_year}: è³‡æ–™éå°‘\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"  ğŸš€ {predict_year}: è¨“ç·´ {min(required_train_years)}-{max(required_train_years)} â†’ é æ¸¬ {predict_year} ({len(train_ag)}/{len(test_ag)} ç­†)\")\n",
        "\n",
        "                if 'predictor' in locals():\n",
        "                    del predictor\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache() if HAS_GPU else None\n",
        "\n",
        "                path_roll.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                try:\n",
        "                    predictor = TabularPredictor(\n",
        "                        label=LABEL, problem_type=\"regression\", eval_metric=\"rmse\", path=str(path_roll),\n",
        "                    ).fit(\n",
        "                        train_data=train_ag, time_limit=TIME_LIMIT, presets=\"best_quality\",\n",
        "                        dynamic_stacking=True, ag_args_fit={'num_gpus': 1} if HAS_GPU else {'num_gpus': 0}\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(f\"  âŒ è¨“ç·´éŒ¯èª¤ {predict_year}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                preds = predictor.predict(test_ag)\n",
        "                y_true = test_ag[LABEL].values\n",
        "                y_pred = np.asarray(preds)\n",
        "                rmse = float(np.sqrt(np.mean((y_pred - y_true) ** 2)))\n",
        "                sharpe = compute_sharpe_backtest(y_true, y_pred)\n",
        "\n",
        "                lb = predictor.leaderboard(test_ag, silent=True)\n",
        "                model_names = lb[\"model\"].tolist()\n",
        "                model_perf_rows = []\n",
        "                pred_cols = {\"date\": test_df.loc[test_ag.index][\"date\"].values, LABEL: y_true, \"pred_best\": y_pred}\n",
        "\n",
        "                for model_name in model_names:\n",
        "                    try:\n",
        "                        preds_m = np.asarray(predictor.predict(test_ag, model=model_name))\n",
        "                        safe_name = model_name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
        "                        pred_cols[f\"pred_{safe_name}\"] = preds_m\n",
        "                        model_perf_rows.append({\n",
        "                            \"cutoff\": cutoff, \"train_years\": TRAIN_YEARS, \"predict_year\": int(predict_year),\n",
        "                            \"train_period\": f\"{min(required_train_years)}-{max(required_train_years)}\",\n",
        "                            \"model\": model_name, \"rmse\": float(np.sqrt(np.mean((preds_m - y_true) ** 2))),\n",
        "                            \"sharpe\": compute_sharpe_backtest(y_true, preds_m),\n",
        "                        })\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "                df_model_perf = pd.DataFrame(model_perf_rows)\n",
        "                # ç‰¹å¾µé‡è¦æ€§ï¼šåƒ…è¨ˆç®— RMSE å‰3 èˆ‡ Sharpe å‰3ï¼Œå»é‡å¾Œç¯€çœæ™‚é–“\n",
        "                top_rmse = df_model_perf.nsmallest(3, \"rmse\")[\"model\"].tolist()\n",
        "                top_sharpe = df_model_perf.nlargest(3, \"sharpe\")[\"model\"].tolist()\n",
        "                fi_models = list(dict.fromkeys(top_rmse + top_sharpe))\n",
        "                fi_rows = []\n",
        "                for model_name in fi_models:\n",
        "                    try:\n",
        "                        fi_m = predictor.feature_importance(data=test_ag, model=model_name).reset_index().rename(columns={\"index\": \"feature\"})\n",
        "                        fi_m[\"model\"] = model_name\n",
        "                        fi_m[\"predict_year\"] = int(predict_year)\n",
        "                        fi_m[\"train_years\"] = TRAIN_YEARS\n",
        "                        fi_rows.append(fi_m)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                all_models_perf.append(df_model_perf)\n",
        "                lb_with_metrics = lb.merge(\n",
        "                    df_model_perf[[\"model\", \"rmse\", \"sharpe\"]].rename(columns={\"rmse\": \"rmse_test\", \"sharpe\": \"sharpe_test\"}),\n",
        "                    on=\"model\", how=\"left\"\n",
        "                )\n",
        "                df_fi_all = pd.concat(fi_rows, ignore_index=True) if fi_rows else pd.DataFrame()\n",
        "\n",
        "                lb.to_csv(path_roll / \"leaderboard.csv\", index=False)\n",
        "                lb_with_metrics.to_csv(path_roll / \"leaderboard_with_metrics.csv\", index=False)\n",
        "                df_model_perf.to_csv(path_roll / \"models_performance.csv\", index=False)\n",
        "                df_fi_all.to_csv(path_roll / \"feature_importance_all_models.csv\", index=False)\n",
        "\n",
        "                out_pred = test_df.loc[test_ag.index].copy()\n",
        "                out_pred[\"pred\"] = y_pred\n",
        "                out_pred[[\"date\", LABEL, \"pred\"]].to_csv(path_roll / \"predictions.csv\", index=False)\n",
        "\n",
        "                pred_all_df = pd.DataFrame(pred_cols)\n",
        "                pred_all_df.to_csv(path_roll / \"predictions_all_models.csv\", index=False)\n",
        "\n",
        "                metrics = {\n",
        "                    \"cutoff\": cutoff, \"train_years\": TRAIN_YEARS, \"predict_year\": int(predict_year),\n",
        "                    \"train_period\": f\"{min(required_train_years)}-{max(required_train_years)}\",\n",
        "                    \"rmse\": rmse, \"sharpe\": sharpe, \"best_model\": predictor.model_best,\n",
        "                    \"num_models\": len(model_names), \"model_path\": f\"train{TRAIN_YEARS}y/roll_{predict_year}\",\n",
        "                }\n",
        "                with open(path_roll / \"metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "                    json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "                summary_list.append({\n",
        "                    \"cutoff\": cutoff, \"train_years\": TRAIN_YEARS, \"predict_year\": int(predict_year),\n",
        "                    \"train_period\": metrics[\"train_period\"], \"rmse\": rmse, \"sharpe\": sharpe,\n",
        "                    \"best_model\": predictor.model_best, \"num_models\": len(model_names),\n",
        "                    \"model_path\": metrics[\"model_path\"], \"skipped\": False\n",
        "                })\n",
        "                per_year_reports[int(predict_year)] = {\"leaderboard\": lb_with_metrics, \"model_performance\": df_model_perf, \"feature_importance\": df_fi_all}\n",
        "                print(f\"  ğŸ‰ å®Œæˆ {predict_year}: Sharpe={sharpe:.4f}, RMSE={rmse:.5f}, Best={predictor.model_best}\")\n",
        "\n",
        "            if summary_list:\n",
        "                df_summary = pd.DataFrame(summary_list)\n",
        "                df_summary.to_csv(train_out / f\"summary_train{TRAIN_YEARS}y.csv\", index=False)\n",
        "                all_summary.append(df_summary)\n",
        "                excel_path = ROLL_OUTPUT / f\"rolling_models_by_year_train{TRAIN_YEARS}y.xlsx\"\n",
        "                try:\n",
        "                    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
        "                        for year in sorted(per_year_reports.keys()):\n",
        "                            report = per_year_reports[year]\n",
        "                            sheet_name = str(year)[:31]\n",
        "                            startrow = 0\n",
        "                            if not report[\"leaderboard\"].empty:\n",
        "                                pd.DataFrame({\"section\": [\"leaderboard_with_metrics\"]}).to_excel(writer, sheet_name=sheet_name, index=False, header=False, startrow=startrow)\n",
        "                                startrow += 1\n",
        "                                report[\"leaderboard\"].to_excel(writer, sheet_name=sheet_name, index=False, startrow=startrow)\n",
        "                                startrow += len(report[\"leaderboard\"]) + 2\n",
        "                            if not report[\"model_performance\"].empty:\n",
        "                                pd.DataFrame({\"section\": [\"model_performance\"]}).to_excel(writer, sheet_name=sheet_name, index=False, header=False, startrow=startrow)\n",
        "                                startrow += 1\n",
        "                                report[\"model_performance\"].to_excel(writer, sheet_name=sheet_name, index=False, startrow=startrow)\n",
        "                                startrow += len(report[\"model_performance\"]) + 2\n",
        "                            if not report[\"feature_importance\"].empty:\n",
        "                                pd.DataFrame({\"section\": [\"feature_importance_all_models\"]}).to_excel(writer, sheet_name=sheet_name, index=False, header=False, startrow=startrow)\n",
        "                                startrow += 1\n",
        "                                report[\"feature_importance\"].to_excel(writer, sheet_name=sheet_name, index=False, startrow=startrow)\n",
        "                    print(f\"  Excel: {excel_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  âš ï¸ Excel è¼¸å‡ºå¤±æ•—: {e}\")\n",
        "\n",
        "        if all_summary:\n",
        "            combined = pd.concat(all_summary, ignore_index=True)\n",
        "            combined.to_csv(ROLL_OUTPUT / \"summary_all_train_years.csv\", index=False)\n",
        "            print(f\"\\nâœ… å½™ç¸½: {ROLL_OUTPUT / 'summary_all_train_years.csv'}\")\n",
        "            if all_models_perf:\n",
        "                perf_all = pd.concat(all_models_perf, ignore_index=True)\n",
        "                perf_all.to_csv(ROLL_OUTPUT / \"models_performance_all_train_years.csv\", index=False)\n",
        "                print(f\"âœ… æ‰€æœ‰æ¨¡å‹ç´€éŒ„: {ROLL_OUTPUT / 'models_performance_all_train_years.csv'}\")\n",
        "            display(combined)\n",
        "        else:\n",
        "            print(\"\\nâŒ æ²’æœ‰ç”¢ç”Ÿä»»ä½•çµæœï¼Œè«‹æª¢æŸ¥è³‡æ–™æˆ–è·¯å¾‘ã€‚\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMS_Th3bCHgq"
      },
      "source": [
        "## 6. å½™ç¸½è¡¨ï¼ˆæ•¸å€¼è¼¸å‡ºä¾›æœ¬åœ°åˆ†æï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSMPs8g8CHgq",
        "outputId": "8f50d1b6-7909-4feb-a060-e6fb7f60f85d"
      },
      "outputs": [],
      "source": [
        "# å½™ç¸½è¡¨èˆ‡è¼¸å‡ºç”±ä¸Šæ–¹ OUTPUT_ROOT æ±ºå®š\n",
        "from pathlib import Path\n",
        "summary_path = output_root / \"summary_all_train_years.csv\"\n",
        "if summary_path.exists():\n",
        "    display(pd.read_csv(summary_path))\n",
        "else:\n",
        "    print(\"å°šæœªç”¢ç”Ÿå½™ç¸½è¡¨ï¼Œè«‹å…ˆåŸ·è¡Œä¸Šæ–¹æ»¾å‹•è¨“ç·´ cellã€‚\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
