{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Y4IBghCHgk"
      },
      "source": [
        "# AutoGluon 訓練（Colab / 本機）\n",
        "\n",
        "- **輸入**：`merged_for_autogluon_0900.csv`（由 `merge_and_train.py` 產出，含 `target_return` 與壓縮特徵）。\n",
        "- **流程**：讀取合併表 → 去掉 `date`、dropna → 依時間切分 train/val/test → TabularPredictor 迴歸訓練 → 存模型。\n",
        "- **Colab**：請先掛載 Google Drive，並將下方 `DATA_ROOT` 設為含 `output_0900/merged_for_autogluon_0900/` 的目錄（或直接設 `MERGED_CSV_PATH`）。\n",
        "- **本機**：可設 `DATA_ROOT` 為專案 `data/` 路徑，或直接指定 `MERGED_CSV_PATH`。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3I6AI3pCHgm"
      },
      "source": [
        "## 1. 掛載 Google Drive（Colab 必跑；本機可略）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 20557,
          "status": "ok",
          "timestamp": 1770550531199,
          "user": {
            "displayName": "李仲翔",
            "userId": "12877791582067812531"
          },
          "user_tz": -480
        },
        "id": "RsnOGcy5CHgn",
        "outputId": "20575ba7-bd89-4b7e-8443-05b9a27fdeaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Colab: True\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "print(\"Colab:\", IN_COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjGjh9cVCHgo"
      },
      "source": [
        "## 2. 路徑與參數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 179,
          "status": "ok",
          "timestamp": 1770550720978,
          "user": {
            "displayName": "李仲翔",
            "userId": "12877791582067812531"
          },
          "user_tz": -480
        },
        "id": "aNemA6jsCHgo",
        "outputId": "14601ee7-c0e6-4a94-901a-3d173f612034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MERGED_CSV_PATH: /content/drive/MyDrive/2026/論文/Thesis-AutoGluon-TXF-Research/data/merged_for_autogluon_0900/merged_for_autogluon_0900.csv\n",
            "MODEL_SAVE_DIR: /content/drive/MyDrive/Thesis-AutoGluon-TXF-Research/data/output_0900/models/autogluon_merged\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Colab：設為 Drive 上專案 data 目錄，例如 \"/content/drive/MyDrive/Thesis-AutoGluon-TXF-Research/data\"\n",
        "# 本機：設為專案 data 目錄，或留空改設 MERGED_CSV_PATH\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Thesis-AutoGluon-TXF-Research/data\") if IN_COLAB else Path.cwd().resolve().parent.parent / \"data\"\n",
        "\n",
        "# 合併表路徑（若已指定則優先使用，否則用 DATA_ROOT 推）\n",
        "MERGED_CSV_PATH = \"/content/drive/MyDrive/2026/論文/Thesis-AutoGluon-TXF-Research/data/merged_for_autogluon_0900/merged_for_autogluon_0900.csv\"  # 例如 Path(\"/content/drive/.../merged_for_autogluon_0900.csv\")\n",
        "if MERGED_CSV_PATH is None:\n",
        "    MERGED_CSV_PATH = DATA_ROOT / \"output_0900\" / \"merged_for_autogluon_0900\" / \"merged_for_autogluon_0900.csv\"\n",
        "\n",
        "# 模型存檔目錄（寫死：data/models，Colab 時為 Drive 上專案的 data/models）\n",
        "MODEL_SAVE_DIR = DATA_ROOT / \"models\"\n",
        "\n",
        "LABEL = \"target_return\"\n",
        "TIME_LIMIT = 600  # 秒\n",
        "TRAIN_RATIO, VAL_RATIO = 0.6, 0.2  # test = 1 - 0.6 - 0.2 = 0.2\n",
        "\n",
        "# 預先建立模型輸出目錄（若不存在則建立）\n",
        "MODEL_SAVE_DIR = Path(MODEL_SAVE_DIR)\n",
        "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"MERGED_CSV_PATH:\", MERGED_CSV_PATH)\n",
        "print(\"MODEL_SAVE_DIR:\", MODEL_SAVE_DIR)\n",
        "print(\"模型目錄已建立:\", MODEL_SAVE_DIR.exists())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwJIqJf4CHgp"
      },
      "source": [
        "## 3. 安裝 AutoGluon（Colab 通常需執行一次）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 19978,
          "status": "ok",
          "timestamp": 1770550744832,
          "user": {
            "displayName": "李仲翔",
            "userId": "12877791582067812531"
          },
          "user_tz": -480
        },
        "id": "Fd4N28sOCHgp",
        "outputId": "8d92d581-ab89-4f05-d347-b066c32ca9d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/515.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m358.4/515.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install autogluon.tabular --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8rB07Y5CHgp"
      },
      "source": [
        "## 4. 載入資料、去 date、dropna、切分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 804,
          "status": "ok",
          "timestamp": 1770550783597,
          "user": {
            "displayName": "李仲翔",
            "userId": "12877791582067812531"
          },
          "user_tz": -480
        },
        "id": "FCuP06qXCHgq",
        "outputId": "a63e0186-3baa-451d-a1f3-bd098951bcb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after drop date + dropna: (2271, 50)\n",
            "Train: 1362, Val: 454, Test: 455\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(MERGED_CSV_PATH)\n",
        "df = df.drop(columns=[\"date\", \"datetime\"], errors=\"ignore\").dropna()\n",
        "print(\"Shape after drop date + dropna:\", df.shape)\n",
        "if LABEL not in df.columns:\n",
        "    raise ValueError(f\"No column '{LABEL}' in CSV.\")\n",
        "\n",
        "n = len(df)\n",
        "train_end = int(n * TRAIN_RATIO)\n",
        "val_end = int(n * (TRAIN_RATIO + VAL_RATIO))\n",
        "train_data = df.iloc[:train_end]\n",
        "val_data = df.iloc[train_end:val_end]\n",
        "test_data = df.iloc[val_end:]\n",
        "# best_quality 袋裝模式要求把 train+val 一起當 train_data，不另傳 tuning_data\n",
        "train_data_for_fit = pd.concat([train_data, val_data], ignore_index=True)\n",
        "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
        "print(f\"Train for fit (train+val): {len(train_data_for_fit)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**若出現「Learner is already fit」**：表示 `path` 指向的目錄裡已有先前訓練的模型，AutoGluon 會載入該模型，因此不能再呼叫 `.fit()`。  \n",
        "**解法**：上方參數設 `USE_TIMESTAMPED_DIR = True`（預設），每次訓練會存到新子目錄（如 `autogluon_merged/20250124_123456`），即不會載到舊模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkCcaWNXCHgq"
      },
      "source": [
        "## 5. 訓練並存檔"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 1898,
          "status": "error",
          "timestamp": 1770550953765,
          "user": {
            "displayName": "李仲翔",
            "userId": "12877791582067812531"
          },
          "user_tz": -480
        },
        "id": "RwBDokhCCHgq",
        "outputId": "4c23b82e-853f-40af-877c-b680231b5cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/drive/MyDrive/Thesis-AutoGluon-TXF-Research/data/output_0900/models/autogluon_merged\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.5.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Pytorch Version:    2.9.0+cpu\n",
            "CUDA Version:       CUDA is not available\n",
            "Memory Avail:       11.35 GB / 12.67 GB (89.6%)\n",
            "Disk Space Avail:   82.12 GB / 107.72 GB (76.2%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
            "/usr/local/lib/python3.12/dist-packages/autogluon/tabular/predictor/predictor.py:1493: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ImportError('ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.43.0,<2.53.0\"`')\n",
            "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
            "\t\tContext path: \"/content/drive/MyDrive/Thesis-AutoGluon-TXF-Research/data/output_0900/models/autogluon_merged/ds_sub_fit/sub_fit_ho\"\n",
            "Running DyStack sub-fit ...\n",
            "Beginning AutoGluon training ... Time limit = 150s\n",
            "AutoGluon will save models to \"/content/drive/MyDrive/Thesis-AutoGluon-TXF-Research/data/output_0900/models/autogluon_merged/ds_sub_fit/sub_fit_ho\"\n",
            "Train Data Rows:    1210\n",
            "Train Data Columns: 49\n",
            "Tuning Data Rows:    454\n",
            "Tuning Data Columns: 49\n",
            "Label Column:       target_return\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11623.77 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.62 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUnused Original Features (Count: 15): ['BBANDS_compressed_0_min', 'BBANDS_compressed_0_max', 'BBANDS_compressed_0_median', 'MACD_compressed_0_min', 'MACD_compressed_0_max', 'MACD_compressed_0_median', 'STOCHF_compressed_0_min', 'STOCHF_compressed_0_max', 'STOCHF_compressed_0_median', 'STOCHRSI_compressed_0_min', 'STOCHRSI_compressed_0_max', 'STOCHRSI_compressed_0_median', 'STOCH_compressed_0_min', 'STOCH_compressed_0_max', 'STOCH_compressed_0_median']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 15 | ['BBANDS_compressed_0_min', 'BBANDS_compressed_0_max', 'BBANDS_compressed_0_median', 'MACD_compressed_0_min', 'MACD_compressed_0_max', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 27 | ['open_mean', 'open_std', 'high_std', 'low_mean', 'low_std', ...]\n",
            "\t\t('int', [])   :  7 | ['open_min', 'high_min', 'low_min', 'low_max', 'close_min', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 27 | ['open_mean', 'open_std', 'high_std', 'low_mean', 'low_std', ...]\n",
            "\t\t('int', [])   :  7 | ['open_min', 'high_min', 'low_min', 'low_max', 'close_min', ...]\n",
            "\t0.1s = Fit runtime\n",
            "\t34 features in original data used to generate 34 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.43 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Warning: Exception encountered during DyStack sub-fit:\n",
            "\tX_val, y_val is not None, but bagged mode was specified. If calling from `TabularPredictor.fit()`, `tuning_data` should be None.\n",
            "Default bagged mode does not use tuning data / validation data. Instead, all data (`train_data` and `tuning_data`) should be combined and specified as `train_data`.\n",
            "To avoid this error and use `tuning_data` as holdout data in bagged mode, specify the following:\n",
            "\tpredictor.fit(..., tuning_data=tuning_data, use_bag_holdout=True)\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t1s\t = DyStack   runtime |\t599s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Learner is already fit.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1119165447.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTIME_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/common/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_post_fit_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learner is already fit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Learner is already fit."
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "import shutil\n",
        "\n",
        "MODEL_SAVE_DIR = Path(MODEL_SAVE_DIR)\n",
        "# 訓練前清空目錄，避免 path 已有舊模型被載入而觸發 AssertionError: Learner is already fit\n",
        "if MODEL_SAVE_DIR.exists():\n",
        "    shutil.rmtree(MODEL_SAVE_DIR)\n",
        "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "predictor = TabularPredictor(\n",
        "    label=LABEL,\n",
        "    problem_type=\"regression\",\n",
        "    eval_metric=\"rmse\",\n",
        "    path=str(MODEL_SAVE_DIR),\n",
        ").fit(\n",
        "    train_data_for_fit,\n",
        "    time_limit=TIME_LIMIT,\n",
        "    presets=\"best_quality\",\n",
        ")\n",
        "print(\"Training done. Model saved to:\", MODEL_SAVE_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMS_Th3bCHgq"
      },
      "source": [
        "## 6. 驗證集 / 測試集評估（可選）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSMPs8g8CHgq"
      },
      "outputs": [],
      "source": [
        "print(\"=== Leaderboard (validation) ===\")\n",
        "print(predictor.leaderboard(val_data, silent=True))\n",
        "print(\"\\n=== Leaderboard (test) ===\")\n",
        "print(predictor.leaderboard(test_data, silent=True))\n",
        "print(\"\\n=== Evaluate on test ===\")\n",
        "print(predictor.evaluate(test_data))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
